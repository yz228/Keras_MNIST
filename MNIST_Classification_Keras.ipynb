{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use a simple neural network to classify hand-written digits.\n",
    "\n",
    "The MNIST dataset consists of images of hand-written digits (0-9) as well as their corresponding labels. We will use a simple shallow neural network implemented in Keras to identify the hand-written digits.\n",
    "Again, let's first import all the libraries needed for this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,BatchNormalization,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define some functions to help read in the dataset and convert labels to one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = load_dataset()\n",
    "\n",
    "# load Parameters\n",
    "X_train = X_train_orig.T\n",
    "X_test = X_test_orig.T\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 10).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what the dataset looks like. The X_train and X_test data are of shapes [784, 20000] and [784, 10000] respectively. The first dimension (784) is a flattened out [28x28] containing one hand-written digit image, and the second dimension is the number of images in the dataset (20000 images in the training set, 10000 images in the test set). The Y_train and Y_test are the labels in the shape of [1, 20000] and [1, 10000]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_orig.shape)\n",
    "print(Y_train_orig.shape)\n",
    "print(X_test_orig.shape)\n",
    "print(Y_test_orig.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can display an image in the training set as well as its corresponding label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a demo image\n",
    "idx = 0                                             # the index of the image to display\n",
    "demoimage = np.reshape(X_train[idx,:], ((28,28)))   # reshape the image to 28x28\n",
    "plt.imshow(demoimage, cmap='gray')                  # display image in grayscale\n",
    "plt.show() \n",
    "\n",
    "print(Y_train_orig[0,idx])                          # display the corresponding label of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Keras model to train the dataset. It consists of 4 Dense layers with BatchNorm and Dropouts, the output layer is a Dense layer with a softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_dim=784, kernel_initializer=glorot_uniform()))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, kernel_initializer=glorot_uniform()))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(64, kernel_initializer=glorot_uniform()))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(32, kernel_initializer=glorot_uniform()))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a learning rate scheduler for adjustable learning rate tuning during different epochs, as well as a custom Adam optimizer for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch == 10:\n",
    "        K.set_value(model.optimizer.lr, 0.0003)\n",
    "    elif epoch == 20:\n",
    "        K.set_value(model.optimizer.lr, 0.0001)\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "change_lr = LearningRateScheduler(scheduler,verbose=1)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model and start training. We'll plot the change in loss and accuracy during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "          epochs=3,\n",
    "          batch_size=64, \n",
    "          callbacks=[change_lr])\n",
    "\n",
    "# List all data stored in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# Plot the change in accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot the change in loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's evaluate how well the system perform on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model w/test data\n",
    "preds  =  model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
